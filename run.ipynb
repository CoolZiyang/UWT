{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize folder and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start time: 2018-05-18 16:07:04\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "assert torch.cuda.is_available(), \"torch.cuda is not available\"\n",
    "\n",
    "## create experiment folder\n",
    "log_dir = os.path.join(os.getcwd(),'log')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "exp_dir = os.path.join(log_dir, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "\n",
    "## set up logger\n",
    "log_file = os.path.join(exp_dir, 'train.log')\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "logger.info('Start time: %s' % datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Argument List =====\n",
      "Source Language: en\n",
      "Target Language: es\n",
      "Embedding Dimension: 300\n",
      "Vocabulary Size (for both): 200000\n",
      "Discriminator Hidden Layer Dimension: 2048\n",
      "Discriminator Hidden Dropout: 0.00\n",
      "Discriminator Input Dropout: 0.10\n",
      "Learning Rate: 0.10\n",
      "Decay: 0.95\n",
      "Number of Epochs: 50\n",
      "Number of Iterations per Epoch: 200000\n",
      "Batch Size: 200000\n",
      "Number of Steps for Discriminator: 200000\n",
      "Number of Most Frequent Words Fed into Discriminator: 75000\n",
      "Discriminator Smothiness: 0.1\n",
      "Orthogonality Update Coefficient: 0.001\n"
     ]
    }
   ],
   "source": [
    "src_emb_file = './data/wiki.en.vec'\n",
    "tgt_emb_file = './data/wiki.es.vec'\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'es'\n",
    "emb_dim = 300\n",
    "max_voc = 200000\n",
    "\n",
    "dis_hid_dim = 2048\n",
    "dis_dropout = 0.\n",
    "dis_input_dropout = 0.1\n",
    "lr = 0.1\n",
    "decay = 0.95\n",
    "\n",
    "n_epochs = 50\n",
    "epoch_size = 200000\n",
    "batch_size = 32\n",
    "dis_steps = 5\n",
    "dis_most_frequent = 75000\n",
    "dis_smooth = 0.1\n",
    "map_beta = 0.001\n",
    "\n",
    "logger.info('===== Argument List =====')\n",
    "logger.info('Source Language: %s' % src_lang)\n",
    "logger.info('Target Language: %s' % tgt_lang)\n",
    "logger.info('Embedding Dimension: %i' % emb_dim)\n",
    "logger.info('Vocabulary Size (for both): %i' % max_voc)\n",
    "logger.info('Discriminator Hidden Layer Dimension: %i' % dis_hid_dim)\n",
    "logger.info('Discriminator Hidden Dropout: %.2f' % dis_dropout)\n",
    "logger.info('Discriminator Input Dropout: %.2f' % dis_input_dropout)\n",
    "logger.info('Learning Rate: %.2f' % lr)\n",
    "logger.info('Decay: %.2f' % decay)\n",
    "logger.info('Number of Epochs: %i' % n_epochs)\n",
    "logger.info('Number of Iterations per Epoch: %i' % epoch_size)\n",
    "logger.info('Batch Size: %i' % epoch_size)\n",
    "logger.info('Number of Steps for Discriminator: %i' % epoch_size)\n",
    "logger.info('Number of Most Frequent Words Fed into Discriminator: %i' % dis_most_frequent)\n",
    "logger.info('Discriminator Smothiness: %.1f' % dis_smooth)\n",
    "logger.info('Orthogonality Update Coefficient: %.3f' % map_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loaded 200000 pre-trained en word embeddings\n",
      "loaded 200000 pre-trained es word embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3075e-01, -8.7659e-02, -1.1427e-01,  ..., -4.0476e-02,\n",
       "         -1.2293e-02,  4.2569e-02],\n",
       "        [-3.6446e-01,  9.5962e-02, -1.6188e-01,  ..., -1.4986e-01,\n",
       "          2.3584e-01,  1.8541e-01],\n",
       "        [-5.9110e-02, -8.3343e-02, -9.3019e-02,  ..., -5.4064e-02,\n",
       "          1.7285e-01,  1.6713e-01],\n",
       "        ...,\n",
       "        [ 3.2125e-01,  1.3622e-01, -5.0101e-01,  ...,  1.4182e-01,\n",
       "          5.0989e-01,  2.2007e-01],\n",
       "        [-4.6783e-01, -7.4949e-01, -4.4708e-02,  ...,  9.5594e-01,\n",
       "         -3.6959e-01,  1.0554e-01],\n",
       "        [-7.4782e-02, -3.6216e-01, -1.8766e-01,  ..., -2.3346e-01,\n",
       "          6.2097e-02, -2.3693e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "from dict import Dictionary\n",
    "\n",
    "def load_embedding(file, tag):\n",
    "    word2id = {}\n",
    "    vectors = []\n",
    "    with io.open(file, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                split = line.split()\n",
    "                assert len(split) == 2\n",
    "                assert emb_dim == int(split[1])\n",
    "            else:\n",
    "                if len(word2id) >= max_voc:\n",
    "                    break\n",
    "                word, vect = line.rstrip().split(' ', 1)\n",
    "                word = word.lower()\n",
    "                vect = np.fromstring(vect, sep=' ')\n",
    "                if np.linalg.norm(vect) == 0:\n",
    "                    vect[0] = 0.01\n",
    "                if word in word2id:\n",
    "                    logger.warning(\"word %s appears twice in the %s embedding\" % (word, 'source'))\n",
    "                    continue\n",
    "                else:\n",
    "                    if not vect.shape == (emb_dim,):\n",
    "                        logger.warning(\"invalid dimension (%i,) for %s word %s\" % (vect.shape[0], tag, word))\n",
    "                        continue\n",
    "                    word2id[word] = len(word2id)\n",
    "                    vectors.append(vect[None])\n",
    "    assert len(word2id) == len(vectors)\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    dico = Dictionary(id2word, word2id, tag)\n",
    "    embeddings = np.concatenate(vectors, 0)\n",
    "    embeddings = torch.from_numpy(embeddings).float()\n",
    "    embeddings = embeddings.cuda()\n",
    "    logger.info(\"loaded %i pre-trained %s word embeddings\" % (len(vectors), tag))\n",
    "    \n",
    "    return dico, embeddings\n",
    "\n",
    "## load source embedding\n",
    "src_dico, _src_emb = load_embedding(src_emb_file, src_lang)\n",
    "src_emb = torch.nn.Embedding(len(src_dico), emb_dim, sparse=True)\n",
    "src_emb.weight.data.copy_(_src_emb)\n",
    "\n",
    "## load target embedding\n",
    "tgt_dico, _tgt_emb = load_embedding(tgt_emb_file, tgt_lang)\n",
    "tgt_emb = torch.nn.Embedding(len(tgt_dico), emb_dim, sparse=True)\n",
    "tgt_emb.weight.data.copy_(_tgt_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (layers): Sequential(\n",
       "    (0): Dropout(p=0.1)\n",
       "    (1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Dropout(p=0.0)\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Dropout(p=0.0)\n",
       "    (7): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generator\n",
    "mapping = torch.nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "mapping.weight.data.copy_(torch.diag(torch.ones(emb_dim)))\n",
    "\n",
    "# Discriminator\n",
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layers = [torch.nn.Dropout(dis_input_dropout)]\n",
    "        self.layers.append(torch.nn.Linear(emb_dim, dis_hid_dim))\n",
    "        self.layers.append(torch.nn.LeakyReLU(0.2))\n",
    "        self.layers.append(torch.nn.Dropout(dis_dropout))\n",
    "        self.layers.append(torch.nn.Linear(dis_hid_dim, dis_hid_dim))\n",
    "        self.layers.append(torch.nn.LeakyReLU(0.2))\n",
    "        self.layers.append(torch.nn.Dropout(dis_dropout))\n",
    "        self.layers.append(torch.nn.Linear(dis_hid_dim, 1))\n",
    "        self.layers.append(torch.nn.Sigmoid())\n",
    "        self.layers = torch.nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "            assert x.dim() == 2 and x.size(1) == emb_dim\n",
    "            return self.layers(x).view(-1)\n",
    "\n",
    "discriminator = Discriminator()\n",
    "        \n",
    "# Cuda\n",
    "src_emb.cuda()\n",
    "tgt_emb.cuda()\n",
    "mapping.cuda()\n",
    "discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "optimizer_g = optim.SGD(mapping.parameters(), lr)\n",
    "optimizer_d = optim.SGD(discriminator.parameters(), lr)\n",
    "lambda_ = lambda epoch: decay ** epoch\n",
    "scheduler_g = LambdaLR(optimizer_g, lr_lambda=[lambda_])\n",
    "scheduler_d = LambdaLR(optimizer_d, lr_lambda=[lambda_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== ADVERSARIAL TRAINING =====\n",
      "\n",
      "start epoch 0\n",
      "iteration 0, loss 0.6626\n",
      "iteration 12000, loss 0.4874\n",
      "iteration 24000, loss 0.5148\n",
      "iteration 36000, loss 0.4164\n",
      "iteration 48000, loss 0.4684\n",
      "iteration 60000, loss 0.4093\n",
      "iteration 72000, loss 0.4104\n",
      "iteration 84000, loss 0.4136\n",
      "iteration 96000, loss 0.4455\n",
      "iteration 108000, loss 0.4805\n",
      "iteration 120000, loss 0.3914\n",
      "iteration 132000, loss 0.4168\n",
      "iteration 144000, loss 0.4113\n",
      "iteration 156000, loss 0.3925\n",
      "iteration 168000, loss 0.3837\n",
      "iteration 180000, loss 0.4212\n",
      "iteration 192000, loss 0.4034\n",
      "csls unsupervised metric score: -0.01453\n",
      "cross-lingual word similarity score average: 0.24641\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 0.369748\n",
      "1500 unique source words - nn - Precision at k = 1: 0.733333\n",
      "2975 source words - nn - Precision at k = 5: 1.075630\n",
      "1500 unique source words - nn - Precision at k = 5: 2.000000\n",
      "2975 source words - nn - Precision at k = 10: 1.579832\n",
      "1500 unique source words - nn - Precision at k = 10: 2.933333\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 0.436975\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 0.866667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 1.714286\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 3.266667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 2.521008\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 4.600000\n",
      "\n",
      "start epoch 1\n",
      "iteration 0, loss 0.4537\n",
      "iteration 12000, loss 0.4307\n",
      "iteration 24000, loss 0.3913\n",
      "iteration 36000, loss 0.4435\n",
      "iteration 48000, loss 0.4022\n",
      "iteration 60000, loss 0.4290\n",
      "iteration 72000, loss 0.4327\n",
      "iteration 84000, loss 0.4060\n",
      "iteration 96000, loss 0.4814\n",
      "iteration 108000, loss 0.4250\n",
      "iteration 120000, loss 0.4307\n",
      "iteration 132000, loss 0.3890\n",
      "iteration 144000, loss 0.4314\n",
      "iteration 156000, loss 0.4681\n",
      "iteration 168000, loss 0.4501\n",
      "iteration 180000, loss 0.4304\n",
      "iteration 192000, loss 0.4347\n",
      "csls unsupervised metric score: 0.06369\n",
      "cross-lingual word similarity score average: 0.64614\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 24.840336\n",
      "1500 unique source words - nn - Precision at k = 1: 49.266667\n",
      "2975 source words - nn - Precision at k = 5: 46.184874\n",
      "1500 unique source words - nn - Precision at k = 5: 66.400000\n",
      "2975 source words - nn - Precision at k = 10: 53.714286\n",
      "1500 unique source words - nn - Precision at k = 10: 71.333333\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 29.815126\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 59.133333\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 54.218487\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 74.933333\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 62.050420\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 80.266667\n",
      "\n",
      "start epoch 2\n",
      "iteration 0, loss 0.4119\n",
      "iteration 12000, loss 0.4564\n",
      "iteration 24000, loss 0.4092\n",
      "iteration 36000, loss 0.4342\n",
      "iteration 48000, loss 0.4341\n",
      "iteration 60000, loss 0.4306\n",
      "iteration 72000, loss 0.4245\n",
      "iteration 84000, loss 0.4340\n",
      "iteration 96000, loss 0.4183\n",
      "iteration 108000, loss 0.4137\n",
      "iteration 120000, loss 0.4072\n",
      "iteration 132000, loss 0.4025\n",
      "iteration 144000, loss 0.4109\n",
      "iteration 156000, loss 0.4260\n",
      "iteration 168000, loss 0.4049\n",
      "iteration 180000, loss 0.4289\n",
      "iteration 192000, loss 0.4024\n",
      "csls unsupervised metric score: 0.11957\n",
      "cross-lingual word similarity score average: 0.66726\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 32.705882\n",
      "1500 unique source words - nn - Precision at k = 1: 64.866667\n",
      "2975 source words - nn - Precision at k = 5: 57.008403\n",
      "1500 unique source words - nn - Precision at k = 5: 80.066667\n",
      "2975 source words - nn - Precision at k = 10: 63.966387\n",
      "1500 unique source words - nn - Precision at k = 10: 83.200000\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 36.537815\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 72.466667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 63.394958\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 85.866667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 70.655462\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 88.666667\n",
      "\n",
      "start epoch 3\n",
      "iteration 0, loss 0.3878\n",
      "iteration 12000, loss 0.4002\n",
      "iteration 24000, loss 0.3996\n",
      "iteration 36000, loss 0.3753\n",
      "iteration 48000, loss 0.4005\n",
      "iteration 60000, loss 0.4068\n",
      "iteration 72000, loss 0.3841\n",
      "iteration 84000, loss 0.4323\n",
      "iteration 96000, loss 0.3806\n",
      "iteration 108000, loss 0.3863\n",
      "iteration 120000, loss 0.4122\n",
      "iteration 132000, loss 0.4020\n",
      "iteration 144000, loss 0.4138\n",
      "iteration 156000, loss 0.3772\n",
      "iteration 168000, loss 0.4044\n",
      "iteration 180000, loss 0.4375\n",
      "iteration 192000, loss 0.3952\n",
      "csls unsupervised metric score: 0.13216\n",
      "cross-lingual word similarity score average: 0.67845\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 34.588235\n",
      "1500 unique source words - nn - Precision at k = 1: 68.600000\n",
      "2975 source words - nn - Precision at k = 5: 59.327731\n",
      "1500 unique source words - nn - Precision at k = 5: 82.400000\n",
      "2975 source words - nn - Precision at k = 10: 66.756303\n",
      "1500 unique source words - nn - Precision at k = 10: 86.400000\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 38.016807\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 75.400000\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 64.773109\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 86.800000\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 72.033613\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 89.866667\n",
      "\n",
      "start epoch 4\n",
      "iteration 0, loss 0.3858\n",
      "iteration 12000, loss 0.3977\n",
      "iteration 24000, loss 0.4101\n",
      "iteration 36000, loss 0.3933\n",
      "iteration 48000, loss 0.4017\n",
      "iteration 60000, loss 0.4076\n",
      "iteration 72000, loss 0.3769\n",
      "iteration 84000, loss 0.4367\n",
      "iteration 96000, loss 0.3702\n",
      "iteration 108000, loss 0.3803\n",
      "iteration 120000, loss 0.3699\n",
      "iteration 132000, loss 0.3678\n",
      "iteration 144000, loss 0.4005\n",
      "iteration 156000, loss 0.4260\n",
      "iteration 168000, loss 0.3988\n",
      "iteration 180000, loss 0.3974\n",
      "iteration 192000, loss 0.3831\n",
      "csls unsupervised metric score: 0.11974\n",
      "cross-lingual word similarity score average: 0.68383\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 32.739496\n",
      "1500 unique source words - nn - Precision at k = 1: 64.933333\n",
      "2975 source words - nn - Precision at k = 5: 57.277311\n",
      "1500 unique source words - nn - Precision at k = 5: 80.133333\n",
      "2975 source words - nn - Precision at k = 10: 64.806723\n",
      "1500 unique source words - nn - Precision at k = 10: 83.666667\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 36.974790\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 73.333333\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 63.495798\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 85.933333\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 71.058824\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 88.800000\n",
      "\n",
      "start epoch 5\n",
      "iteration 0, loss 0.3779\n",
      "iteration 12000, loss 0.3701\n",
      "iteration 24000, loss 0.4008\n",
      "iteration 36000, loss 0.4227\n",
      "iteration 48000, loss 0.3850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration 60000, loss 0.3861\n",
      "iteration 72000, loss 0.4044\n",
      "iteration 84000, loss 0.3845\n",
      "iteration 96000, loss 0.4049\n",
      "iteration 108000, loss 0.4086\n",
      "iteration 120000, loss 0.3743\n",
      "iteration 132000, loss 0.3807\n",
      "iteration 144000, loss 0.3832\n",
      "iteration 156000, loss 0.3661\n",
      "iteration 168000, loss 0.3708\n",
      "iteration 180000, loss 0.3933\n",
      "iteration 192000, loss 0.4034\n",
      "csls unsupervised metric score: 0.11282\n",
      "cross-lingual word similarity score average: 0.68847\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 27.697479\n",
      "1500 unique source words - nn - Precision at k = 1: 54.933333\n",
      "2975 source words - nn - Precision at k = 5: 49.008403\n",
      "1500 unique source words - nn - Precision at k = 5: 68.400000\n",
      "2975 source words - nn - Precision at k = 10: 56.605042\n",
      "1500 unique source words - nn - Precision at k = 10: 71.866667\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 30.957983\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 61.400000\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 55.159664\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 74.266667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 63.159664\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 77.600000\n",
      "\n",
      "start epoch 6\n",
      "iteration 0, loss 0.3820\n",
      "iteration 12000, loss 0.4071\n",
      "iteration 24000, loss 0.3689\n",
      "iteration 36000, loss 0.4116\n",
      "iteration 48000, loss 0.3904\n",
      "iteration 60000, loss 0.3706\n",
      "iteration 72000, loss 0.3937\n",
      "iteration 84000, loss 0.3836\n",
      "iteration 96000, loss 0.3886\n",
      "iteration 108000, loss 0.3788\n",
      "iteration 120000, loss 0.3596\n",
      "iteration 132000, loss 0.3838\n",
      "iteration 144000, loss 0.3801\n",
      "iteration 156000, loss 0.3792\n",
      "iteration 168000, loss 0.3640\n",
      "iteration 180000, loss 0.3734\n",
      "iteration 192000, loss 0.3618\n",
      "csls unsupervised metric score: 0.10250\n",
      "cross-lingual word similarity score average: 0.67499\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 26.789916\n",
      "1500 unique source words - nn - Precision at k = 1: 53.133333\n",
      "2975 source words - nn - Precision at k = 5: 48.100840\n",
      "1500 unique source words - nn - Precision at k = 5: 66.600000\n",
      "2975 source words - nn - Precision at k = 10: 55.697479\n",
      "1500 unique source words - nn - Precision at k = 10: 70.866667\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 27.058824\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 53.666667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 51.462185\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 70.133333\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 58.857143\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 74.000000\n",
      "\n",
      "start epoch 8\n",
      "iteration 0, loss 0.3594\n",
      "iteration 12000, loss 0.3844\n",
      "iteration 24000, loss 0.3783\n",
      "iteration 36000, loss 0.3829\n",
      "iteration 48000, loss 0.3855\n",
      "iteration 60000, loss 0.3725\n",
      "iteration 72000, loss 0.3752\n",
      "iteration 84000, loss 0.3654\n",
      "iteration 96000, loss 0.3716\n",
      "iteration 108000, loss 0.3575\n",
      "iteration 120000, loss 0.3590\n",
      "iteration 132000, loss 0.3909\n",
      "iteration 144000, loss 0.3690\n",
      "iteration 156000, loss 0.3705\n",
      "iteration 168000, loss 0.3712\n",
      "iteration 180000, loss 0.3787\n",
      "iteration 192000, loss 0.3706\n",
      "csls unsupervised metric score: 0.08890\n",
      "cross-lingual word similarity score average: 0.66036\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 25.680672\n",
      "1500 unique source words - nn - Precision at k = 1: 50.933333\n",
      "2975 source words - nn - Precision at k = 5: 47.361345\n",
      "1500 unique source words - nn - Precision at k = 5: 67.266667\n",
      "2975 source words - nn - Precision at k = 10: 54.991597\n",
      "1500 unique source words - nn - Precision at k = 10: 72.333333\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 31.058824\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 61.600000\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 56.235294\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 75.866667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 63.193277\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 79.066667\n",
      "\n",
      "start epoch 9\n",
      "iteration 0, loss 0.3552\n",
      "iteration 12000, loss 0.3750\n",
      "iteration 24000, loss 0.3634\n",
      "iteration 36000, loss 0.3667\n",
      "iteration 48000, loss 0.3911\n",
      "iteration 60000, loss 0.3544\n",
      "iteration 72000, loss 0.3579\n",
      "iteration 84000, loss 0.3563\n",
      "iteration 96000, loss 0.3768\n",
      "iteration 108000, loss 0.3699\n",
      "iteration 120000, loss 0.3688\n",
      "iteration 132000, loss 0.3620\n",
      "iteration 144000, loss 0.3679\n",
      "iteration 156000, loss 0.3524\n",
      "iteration 168000, loss 0.3680\n",
      "iteration 180000, loss 0.3637\n",
      "iteration 192000, loss 0.3740\n",
      "csls unsupervised metric score: 0.10650\n",
      "cross-lingual word similarity score average: 0.67289\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 29.478992\n",
      "1500 unique source words - nn - Precision at k = 1: 58.466667\n",
      "2975 source words - nn - Precision at k = 5: 52.369748\n",
      "1500 unique source words - nn - Precision at k = 5: 73.266667\n",
      "2975 source words - nn - Precision at k = 10: 59.731092\n",
      "1500 unique source words - nn - Precision at k = 10: 77.266667\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 33.613445\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 66.666667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 59.428571\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 79.466667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 66.689076\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 83.666667\n",
      "\n",
      "start epoch 10\n",
      "iteration 0, loss 0.3690\n",
      "iteration 12000, loss 0.3773\n",
      "iteration 24000, loss 0.3609\n",
      "iteration 36000, loss 0.3663\n",
      "iteration 48000, loss 0.3688\n",
      "iteration 60000, loss 0.3575\n",
      "iteration 72000, loss 0.3690\n",
      "iteration 84000, loss 0.3590\n",
      "iteration 96000, loss 0.3654\n",
      "iteration 108000, loss 0.3650\n",
      "iteration 120000, loss 0.3499\n",
      "iteration 132000, loss 0.3535\n",
      "iteration 144000, loss 0.3645\n",
      "iteration 156000, loss 0.3502\n",
      "iteration 168000, loss 0.3554\n",
      "iteration 180000, loss 0.3508\n",
      "iteration 192000, loss 0.3469\n",
      "csls unsupervised metric score: 0.09944\n",
      "cross-lingual word similarity score average: 0.66372\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 27.831933\n",
      "1500 unique source words - nn - Precision at k = 1: 55.200000\n",
      "2975 source words - nn - Precision at k = 5: 49.983193\n",
      "1500 unique source words - nn - Precision at k = 5: 71.266667\n",
      "2975 source words - nn - Precision at k = 10: 57.243697\n",
      "1500 unique source words - nn - Precision at k = 10: 75.400000\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 32.571429\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 64.600000\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 57.411765\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 79.200000\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 65.344538\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 82.733333\n",
      "\n",
      "start epoch 11\n",
      "iteration 0, loss 0.3609\n",
      "iteration 12000, loss 0.3547\n",
      "iteration 24000, loss 0.3626\n",
      "iteration 36000, loss 0.3605\n",
      "iteration 48000, loss 0.3551\n",
      "iteration 60000, loss 0.3612\n",
      "iteration 72000, loss 0.3533\n",
      "iteration 84000, loss 0.3671\n",
      "iteration 96000, loss 0.3541\n",
      "iteration 108000, loss 0.3598\n",
      "iteration 120000, loss 0.3570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration 132000, loss 0.3608\n",
      "iteration 144000, loss 0.3708\n",
      "iteration 156000, loss 0.3645\n",
      "iteration 168000, loss 0.3639\n",
      "iteration 180000, loss 0.3627\n",
      "iteration 192000, loss 0.3662\n",
      "csls unsupervised metric score: 0.08568\n",
      "cross-lingual word similarity score average: 0.64951\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 25.445378\n",
      "1500 unique source words - nn - Precision at k = 1: 50.466667\n",
      "2975 source words - nn - Precision at k = 5: 45.512605\n",
      "1500 unique source words - nn - Precision at k = 5: 66.133333\n",
      "2975 source words - nn - Precision at k = 10: 53.647059\n",
      "1500 unique source words - nn - Precision at k = 10: 71.600000\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 29.680672\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 58.866667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 53.882353\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 75.000000\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 61.243697\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 79.200000\n",
      "\n",
      "start epoch 12\n",
      "iteration 0, loss 0.3713\n",
      "iteration 12000, loss 0.3650\n",
      "iteration 24000, loss 0.3629\n",
      "iteration 36000, loss 0.3633\n",
      "iteration 48000, loss 0.3628\n",
      "iteration 60000, loss 0.3659\n",
      "iteration 72000, loss 0.3627\n",
      "iteration 84000, loss 0.3596\n",
      "iteration 96000, loss 0.3529\n",
      "iteration 108000, loss 0.3531\n",
      "iteration 120000, loss 0.3552\n",
      "iteration 132000, loss 0.3478\n",
      "iteration 144000, loss 0.3521\n",
      "iteration 156000, loss 0.3568\n",
      "iteration 168000, loss 0.3658\n",
      "iteration 180000, loss 0.3502\n",
      "iteration 192000, loss 0.3629\n",
      "csls unsupervised metric score: 0.07719\n",
      "cross-lingual word similarity score average: 0.65587\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 23.663866\n",
      "1500 unique source words - nn - Precision at k = 1: 46.933333\n",
      "2975 source words - nn - Precision at k = 5: 44.705882\n",
      "1500 unique source words - nn - Precision at k = 5: 62.933333\n",
      "2975 source words - nn - Precision at k = 10: 52.369748\n",
      "1500 unique source words - nn - Precision at k = 10: 67.733333\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 28.739496\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 57.000000\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 52.436975\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 71.066667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 59.731092\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 76.000000\n",
      "\n",
      "start epoch 13\n",
      "iteration 0, loss 0.3612\n",
      "iteration 12000, loss 0.3549\n",
      "iteration 24000, loss 0.3527\n",
      "iteration 36000, loss 0.3750\n",
      "iteration 48000, loss 0.3648\n",
      "iteration 60000, loss 0.3642\n",
      "iteration 72000, loss 0.3550\n",
      "iteration 84000, loss 0.3580\n",
      "iteration 96000, loss 0.3568\n",
      "iteration 108000, loss 0.3634\n",
      "iteration 120000, loss 0.3480\n",
      "iteration 132000, loss 0.3482\n",
      "iteration 144000, loss 0.3805\n",
      "iteration 156000, loss 0.3657\n",
      "iteration 168000, loss 0.3644\n",
      "iteration 180000, loss 0.3615\n",
      "iteration 192000, loss 0.3539\n",
      "csls unsupervised metric score: 0.00936\n",
      "cross-lingual word similarity score average: 0.58391\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 5.478992\n",
      "1500 unique source words - nn - Precision at k = 1: 10.866667\n",
      "2975 source words - nn - Precision at k = 5: 10.117647\n",
      "1500 unique source words - nn - Precision at k = 5: 19.066667\n",
      "2975 source words - nn - Precision at k = 10: 12.605042\n",
      "1500 unique source words - nn - Precision at k = 10: 22.800000\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 13.344538\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 26.466667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 26.487395\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 44.066667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 32.436975\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 51.266667\n",
      "\n",
      "start epoch 14\n",
      "iteration 0, loss 0.3672\n",
      "iteration 12000, loss 0.3667\n",
      "iteration 24000, loss 0.3578\n",
      "iteration 36000, loss 0.3483\n",
      "iteration 48000, loss 0.3595\n",
      "iteration 60000, loss 0.3661\n",
      "iteration 72000, loss 0.3487\n",
      "iteration 84000, loss 0.3568\n",
      "iteration 96000, loss 0.3461\n",
      "iteration 108000, loss 0.3625\n",
      "iteration 120000, loss 0.3570\n",
      "iteration 132000, loss 0.3504\n",
      "iteration 144000, loss 0.3447\n",
      "iteration 156000, loss 0.3543\n",
      "iteration 168000, loss 0.3466\n",
      "iteration 180000, loss 0.3617\n",
      "iteration 192000, loss 0.3482\n",
      "csls unsupervised metric score: 0.00118\n",
      "cross-lingual word similarity score average: 0.56630\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - nn - Precision at k = 1: 6.352941\n",
      "1500 unique source words - nn - Precision at k = 1: 12.600000\n",
      "2975 source words - nn - Precision at k = 5: 11.663866\n",
      "1500 unique source words - nn - Precision at k = 5: 21.866667\n",
      "2975 source words - nn - Precision at k = 10: 14.151261\n",
      "1500 unique source words - nn - Precision at k = 10: 25.400000\n",
      "found 2975 pairs of words in the dictionary. 0 other pairs contained at least one unknown word (0 in lang1, 0 in lang2)\n",
      "2975 source words - csls_knn_10 - Precision at k = 1: 12.739496\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 1: 25.266667\n",
      "2975 source words - csls_knn_10 - Precision at k = 5: 23.798319\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 5: 41.066667\n",
      "2975 source words - csls_knn_10 - Precision at k = 10: 28.638655\n",
      "1500 unique source words - csls_knn_10 - Precision at k = 10: 46.666667\n",
      "\n",
      "start epoch 15\n",
      "iteration 0, loss 0.3552\n",
      "iteration 12000, loss 0.3462\n",
      "iteration 24000, loss 0.3635\n",
      "iteration 36000, loss 0.3583\n",
      "iteration 48000, loss 0.3492\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.nn import functional\n",
    "from evaluator import get_crosslingual_wordsim_scores\n",
    "from evaluator import get_word_translation_accuracy\n",
    "from evaluator import get_unsupervised_evaluation\n",
    "\n",
    "assert dis_most_frequent <= min(len(src_dico), len(tgt_dico))\n",
    "\n",
    "def get_xy(src_emb, tgt_emb, vol):\n",
    "    src_ids = torch.LongTensor(batch_size).random_(dis_most_frequent).cuda()\n",
    "    tgt_ids = torch.LongTensor(batch_size).random_(dis_most_frequent).cuda()\n",
    "    src_emb_ = src_emb(Variable(src_ids))\n",
    "    tgt_emb_ = tgt_emb(Variable(tgt_ids))\n",
    "    src_emb_ = mapping(Variable(src_emb_.data))\n",
    "    tgt_emb_ = Variable(tgt_emb_.data)\n",
    "    x = torch.cat([src_emb_, tgt_emb_], 0)\n",
    "    y = torch.FloatTensor(2 * batch_size).zero_()\n",
    "    y[:batch_size] = 1 - dis_smooth\n",
    "    y[batch_size:] = dis_smooth\n",
    "    y = Variable(y.cuda())\n",
    "    return x, y\n",
    "\n",
    "eval_list = []\n",
    "logger.info('===== ADVERSARIAL TRAINING =====')\n",
    "for epoch in range(n_epochs):\n",
    "    logger.info('\\nstart epoch %i' % epoch)\n",
    "    \n",
    "    for i_iter in range(0, epoch_size, batch_size):\n",
    "        \n",
    "        ## discriminiator\n",
    "        for i_dis in range(dis_steps):\n",
    "            discriminator.train()\n",
    "            x, y = get_xy(src_emb, tgt_emb, True)\n",
    "            preds = discriminator(Variable(x.data))\n",
    "            loss = functional.binary_cross_entropy(preds, y)\n",
    "            optimizer_d.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "        if i_iter % 3000 == 0:\n",
    "            logger.info('iteration %s, loss %.4f' % (i_iter, loss.data.item()))\n",
    "            \n",
    "        ## generator\n",
    "        discriminator.eval()\n",
    "        x, y = get_xy(src_emb, tgt_emb, False)\n",
    "        preds = discriminator(x)\n",
    "        loss = functional.binary_cross_entropy(preds, 1 - y)\n",
    "        optimizer_g.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_g.step()\n",
    "        W = mapping.weight.data\n",
    "        W.copy_((1 + map_beta) * W - map_beta * W.mm(W.transpose(0, 1).mm(W)))\n",
    "        \n",
    "        if i_iter == 0:\n",
    "            optimizer_d.zero_grad()\n",
    "            scheduler_d.step()\n",
    "            optimizer_g.zero_grad()\n",
    "            scheduler_g.step()\n",
    "        \n",
    "    # unsupervised evaluation metric\n",
    "    unsupervised_score = get_unsupervised_evaluation(src_dico.word2id, mapping(src_emb.weight).data, tgt_dico.word2id, tgt_emb.weight.data, 10)\n",
    "    if len(eval_list)>0 and unsupervised_score < min(eval_list):\n",
    "        for g in optimizer_g.param_groups:\n",
    "            g['lr'] = g['lr']/2\n",
    "        for g in optimizer_d.param_groups:\n",
    "            g['lr'] = g['lr']/2\n",
    "    eval_list.append(unsupervised_score)\n",
    "    logger.info(\"csls unsupervised metric score: %.5f\" % unsupervised_score)\n",
    "    \n",
    "    # cross-lingual similarity evaluation\n",
    "    src_tgt_ws_score = get_crosslingual_wordsim_scores(src_lang, src_dico.word2id, mapping(src_emb.weight).data.cpu().numpy(), \n",
    "                                                        tgt_lang, tgt_dico.word2id, tgt_emb.weight.data.cpu().numpy())\n",
    "    logger.info(\"cross-lingual word similarity score average: %.5f\" % src_tgt_ws_score)\n",
    "    \n",
    "    # word translation evaluation\n",
    "    word_translation_nn_result = get_word_translation_accuracy(src_lang, src_dico.word2id, mapping(src_emb.weight).data, \n",
    "                    tgt_lang, tgt_dico.word2id, tgt_emb.weight.data, 'nn')\n",
    "    word_translation_csls_result = get_word_translation_accuracy(src_lang, src_dico.word2id, mapping(src_emb.weight).data, \n",
    "                    tgt_lang, tgt_dico.word2id, tgt_emb.weight.data, 'csls_knn_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
